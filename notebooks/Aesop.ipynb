{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 387.1/387.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import tensorflow \n",
    "import tensorflow as tf\n",
    "import json \n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import string, os \n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader as api\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow.keras.utils as ku \n",
    "import random\n",
    "import sys\n",
    "# Load vectors directly from the file\n",
    "word_vectors = api.load(\"glove-twitter-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../configs/config.json','r') as cfgFile:\n",
    "    cfg = json.load(cfgFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/processed/verses.txt'\n",
    "with open(data_dir, \"rb\") as fp:   # Unpickling\n",
    "    lyrics = pickle.load(fp)   \n",
    "    \n",
    "def clean_text(txt):\n",
    "    txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n",
    "    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "    return txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i live life lavish and my chain is karats \\n the last name on the train to paris \\n used to be lame then attained the merit \\n so many clothes cant name the fabrics \\n dynamics i want the fame \\n and my name engraved in granites \\n heres his lane now came to grab it \\n you moving sideways change your habits \\n used to rock minks then i changed to rabbit \\n from out the garbage i came from average \\n used to be righteous that changed to savage \\n bang my ratchet like bangkok dangerous \\n 36 chamber fist trianglist \\n watch me mangle this star spanglist \\n rock cowboy wrangler creating mega-hits \\n im from the grain game at my fingertips \\n \\n\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics = np.array(lyrics)       \n",
    "arr = [[clean_text(j) for j in i.split(' \\n ') if len(j) > 1 and '\\n\\n' != j] for i in list(np.array(lyrics)) if len(i.split(' \\n ')) > 0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i live life lavish and my chain is karats',\n",
       " 'the last name on the train to paris',\n",
       " 'used to be lame then attained the merit',\n",
       " 'so many clothes cant name the fabrics',\n",
       " 'dynamics i want the fame',\n",
       " 'and my name engraved in granites',\n",
       " 'heres his lane now came to grab it',\n",
       " 'you moving sideways change your habits',\n",
       " 'used to rock minks then i changed to rabbit',\n",
       " 'from out the garbage i came from average',\n",
       " 'used to be righteous that changed to savage',\n",
       " 'bang my ratchet like bangkok dangerous',\n",
       " '36 chamber fist trianglist',\n",
       " 'watch me mangle this star spanglist',\n",
       " 'rock cowboy wrangler creating megahits',\n",
       " 'im from the grain game at my fingertips']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you got another thing comin if you think me and my man aint sellin',\n",
       " 'got more gold than mr drum and we sellin',\n",
       " 'through welcome to the terrordome niggas are ever wrong',\n",
       " 'thats why you get no ends but just in case',\n",
       " 'you got a death wish for flare for the dramatics',\n",
       " 'theres some static in the attic  hid it looking at it',\n",
       " 'im a matic nice to the fifth power son and im still at it',\n",
       " 'i was about to flip power son til i saw a vision caz']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(arr)\n",
    "arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_list = np.asarray([y for x in arr for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 24],\n",
       " [5, 24, 195],\n",
       " [5, 24, 195, 202],\n",
       " [5, 24, 195, 202, 514],\n",
       " [5, 24, 195, 202, 514, 46],\n",
       " [5, 24, 195, 202, 514, 46, 5],\n",
       " [5, 24, 195, 202, 514, 46, 5, 130],\n",
       " [5, 24, 195, 202, 514, 46, 5, 130, 15],\n",
       " [5, 24, 195, 202, 514, 46, 5, 130, 15, 6],\n",
       " [5, 24, 195, 202, 514, 46, 5, 130, 15, 6, 7]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "corpus = flattened_list #[' '.join(i) for i in arr]\n",
    "def get_sequence_of_tokens(corpus):\n",
    "    ## tokenization\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "    \n",
    "    ## convert data to sequence of tokens \n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "    return input_sequences, total_words\n",
    "\n",
    "inp_sequences, total_words = get_sequence_of_tokens(corpus)\n",
    "inp_sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'i': 2,\n",
       " 'a': 3,\n",
       " 'to': 4,\n",
       " 'you': 5,\n",
       " 'and': 6,\n",
       " 'my': 7,\n",
       " 'in': 8,\n",
       " 'it': 9,\n",
       " 'on': 10,\n",
       " 'of': 11,\n",
       " 'im': 12,\n",
       " 'like': 13,\n",
       " 'that': 14,\n",
       " 'me': 15,\n",
       " 'with': 16,\n",
       " 'your': 17,\n",
       " 'is': 18,\n",
       " 'for': 19,\n",
       " 'up': 20,\n",
       " 'we': 21,\n",
       " 'but': 22,\n",
       " 'they': 23,\n",
       " 'got': 24,\n",
       " 'get': 25,\n",
       " 'this': 26,\n",
       " 'all': 27,\n",
       " 'be': 28,\n",
       " 'so': 29,\n",
       " 'its': 30,\n",
       " 'dont': 31,\n",
       " 'when': 32,\n",
       " 'out': 33,\n",
       " 'no': 34,\n",
       " 'know': 35,\n",
       " 'was': 36,\n",
       " 'aint': 37,\n",
       " 'from': 38,\n",
       " 'just': 39,\n",
       " 'what': 40,\n",
       " 'now': 41,\n",
       " 'shit': 42,\n",
       " 'niggas': 43,\n",
       " 'nigga': 44,\n",
       " 'at': 45,\n",
       " 'if': 46,\n",
       " 'back': 47,\n",
       " 'cause': 48,\n",
       " 'he': 49,\n",
       " 'she': 50,\n",
       " 'see': 51,\n",
       " 'do': 52,\n",
       " 'her': 53,\n",
       " 'can': 54,\n",
       " 'thats': 55,\n",
       " 'never': 56,\n",
       " 'fuck': 57,\n",
       " 'one': 58,\n",
       " 'not': 59,\n",
       " 'make': 60,\n",
       " 'off': 61,\n",
       " 'or': 62,\n",
       " 'then': 63,\n",
       " 'as': 64,\n",
       " 'em': 65,\n",
       " 'them': 66,\n",
       " 'how': 67,\n",
       " 'down': 68,\n",
       " 'some': 69,\n",
       " 'man': 70,\n",
       " 'time': 71,\n",
       " 'go': 72,\n",
       " 'his': 73,\n",
       " 'cant': 74,\n",
       " 'who': 75,\n",
       " 'life': 76,\n",
       " 'these': 77,\n",
       " 'yall': 78,\n",
       " 'bitch': 79,\n",
       " 'take': 80,\n",
       " 'still': 81,\n",
       " 'love': 82,\n",
       " 'by': 83,\n",
       " 'where': 84,\n",
       " 'through': 85,\n",
       " 'about': 86,\n",
       " 'had': 87,\n",
       " 'let': 88,\n",
       " 'right': 89,\n",
       " 'yo': 90,\n",
       " 'yeah': 91,\n",
       " 'say': 92,\n",
       " 'keep': 93,\n",
       " 'have': 94,\n",
       " 'come': 95,\n",
       " 'been': 96,\n",
       " 'more': 97,\n",
       " 'ya': 98,\n",
       " 'put': 99,\n",
       " 'way': 100,\n",
       " 'him': 101,\n",
       " 'want': 102,\n",
       " 'wanna': 103,\n",
       " 'us': 104,\n",
       " 'are': 105,\n",
       " 'tell': 106,\n",
       " 'than': 107,\n",
       " 'could': 108,\n",
       " 'youre': 109,\n",
       " 'need': 110,\n",
       " 'give': 111,\n",
       " 'ill': 112,\n",
       " 'hit': 113,\n",
       " 'here': 114,\n",
       " 'too': 115,\n",
       " 'real': 116,\n",
       " 'only': 117,\n",
       " 'said': 118,\n",
       " 'gotta': 119,\n",
       " 'even': 120,\n",
       " 'every': 121,\n",
       " 'money': 122,\n",
       " 'feel': 123,\n",
       " 'an': 124,\n",
       " 'new': 125,\n",
       " 'black': 126,\n",
       " 'look': 127,\n",
       " 'why': 128,\n",
       " 'will': 129,\n",
       " 'think': 130,\n",
       " 'ass': 131,\n",
       " 'day': 132,\n",
       " 'little': 133,\n",
       " 'while': 134,\n",
       " 'big': 135,\n",
       " 'rap': 136,\n",
       " 'call': 137,\n",
       " 'good': 138,\n",
       " 'god': 139,\n",
       " 'over': 140,\n",
       " 'around': 141,\n",
       " 'live': 142,\n",
       " 'better': 143,\n",
       " 'game': 144,\n",
       " 'mind': 145,\n",
       " 'made': 146,\n",
       " 'same': 147,\n",
       " 'world': 148,\n",
       " 'two': 149,\n",
       " 'before': 150,\n",
       " 'head': 151,\n",
       " 'baby': 152,\n",
       " 'would': 153,\n",
       " 'hard': 154,\n",
       " 'face': 155,\n",
       " 'bout': 156,\n",
       " 'stop': 157,\n",
       " 'people': 158,\n",
       " 'first': 159,\n",
       " 'gon': 160,\n",
       " 'bitches': 161,\n",
       " 'there': 162,\n",
       " 'play': 163,\n",
       " 'run': 164,\n",
       " 'whole': 165,\n",
       " 'did': 166,\n",
       " 'high': 167,\n",
       " 'try': 168,\n",
       " 'into': 169,\n",
       " 'stay': 170,\n",
       " 'name': 171,\n",
       " 'hold': 172,\n",
       " 'girl': 173,\n",
       " 'really': 174,\n",
       " 'came': 175,\n",
       " 'well': 176,\n",
       " 'our': 177,\n",
       " 'watch': 178,\n",
       " 'uh': 179,\n",
       " 'show': 180,\n",
       " 'leave': 181,\n",
       " 'might': 182,\n",
       " 'used': 183,\n",
       " 'wont': 184,\n",
       " 'oh': 185,\n",
       " 'til': 186,\n",
       " 'their': 187,\n",
       " 'flow': 188,\n",
       " 'eyes': 189,\n",
       " 'rock': 190,\n",
       " 'talk': 191,\n",
       " 'home': 192,\n",
       " 'young': 193,\n",
       " 'night': 194,\n",
       " 'another': 195,\n",
       " 'long': 196,\n",
       " 'getting': 197,\n",
       " 'fucking': 198,\n",
       " 'thought': 199,\n",
       " 'top': 200,\n",
       " 'old': 201,\n",
       " 'thing': 202,\n",
       " 'last': 203,\n",
       " 'whats': 204,\n",
       " 'told': 205,\n",
       " 'best': 206,\n",
       " 'ive': 207,\n",
       " 'ever': 208,\n",
       " 'check': 209,\n",
       " 'always': 210,\n",
       " 'were': 211,\n",
       " 'hear': 212,\n",
       " 'damn': 213,\n",
       " 'bad': 214,\n",
       " 'much': 215,\n",
       " 'left': 216,\n",
       " 'smoke': 217,\n",
       " 'trying': 218,\n",
       " 'die': 219,\n",
       " 'hot': 220,\n",
       " 'boy': 221,\n",
       " 'tryna': 222,\n",
       " 'dick': 223,\n",
       " 'gonna': 224,\n",
       " 'done': 225,\n",
       " 'heart': 226,\n",
       " 'bring': 227,\n",
       " 'theres': 228,\n",
       " 'spit': 229,\n",
       " 'nothing': 230,\n",
       " 'turn': 231,\n",
       " 'work': 232,\n",
       " 'beat': 233,\n",
       " 'own': 234,\n",
       " 'find': 235,\n",
       " 'again': 236,\n",
       " 'next': 237,\n",
       " 'move': 238,\n",
       " 'lets': 239,\n",
       " 'kid': 240,\n",
       " 'many': 241,\n",
       " 'white': 242,\n",
       " 'though': 243,\n",
       " 'since': 244,\n",
       " 'start': 245,\n",
       " 'streets': 246,\n",
       " 'seen': 247,\n",
       " 'hoes': 248,\n",
       " 'kill': 249,\n",
       " 'dead': 250,\n",
       " 'inside': 251,\n",
       " 'am': 252,\n",
       " 'son': 253,\n",
       " 'living': 254,\n",
       " 'because': 255,\n",
       " 'drop': 256,\n",
       " 'lot': 257,\n",
       " 'everybody': 258,\n",
       " 'other': 259,\n",
       " 'style': 260,\n",
       " 'block': 261,\n",
       " 'hell': 262,\n",
       " 'blow': 263,\n",
       " 'mean': 264,\n",
       " 'fuckin': 265,\n",
       " 'everything': 266,\n",
       " 'took': 267,\n",
       " 'mad': 268,\n",
       " 'full': 269,\n",
       " 'something': 270,\n",
       " 'should': 271,\n",
       " 'light': 272,\n",
       " 'catch': 273,\n",
       " 'fly': 274,\n",
       " 'straight': 275,\n",
       " 'hood': 276,\n",
       " 'hate': 277,\n",
       " 'away': 278,\n",
       " 'soul': 279,\n",
       " 'hand': 280,\n",
       " 'kids': 281,\n",
       " 'heard': 282,\n",
       " 'word': 283,\n",
       " 'street': 284,\n",
       " 'pop': 285,\n",
       " 'things': 286,\n",
       " 'walk': 287,\n",
       " 'didnt': 288,\n",
       " 'body': 289,\n",
       " 'pussy': 290,\n",
       " 'after': 291,\n",
       " 'break': 292,\n",
       " 'mic': 293,\n",
       " 'looking': 294,\n",
       " 'ima': 295,\n",
       " 'roll': 296,\n",
       " 'gun': 297,\n",
       " 'years': 298,\n",
       " 'city': 299,\n",
       " 'death': 300,\n",
       " 'most': 301,\n",
       " 'pull': 302,\n",
       " 'listen': 303,\n",
       " 'went': 304,\n",
       " 'gone': 305,\n",
       " 'those': 306,\n",
       " 'going': 307,\n",
       " 'enough': 308,\n",
       " 'cut': 309,\n",
       " 'gettin': 310,\n",
       " 'couldnt': 311,\n",
       " 'blood': 312,\n",
       " 'shot': 313,\n",
       " 'lost': 314,\n",
       " 'three': 315,\n",
       " 'place': 316,\n",
       " 'any': 317,\n",
       " 'rhyme': 318,\n",
       " 'cold': 319,\n",
       " 'change': 320,\n",
       " 'deep': 321,\n",
       " 'guess': 322,\n",
       " 'without': 323,\n",
       " 'days': 324,\n",
       " 'free': 325,\n",
       " 'set': 326,\n",
       " 'believe': 327,\n",
       " 'ride': 328,\n",
       " 'crack': 329,\n",
       " 'throw': 330,\n",
       " 'eat': 331,\n",
       " 'until': 332,\n",
       " 'open': 333,\n",
       " 'house': 334,\n",
       " 'front': 335,\n",
       " 'hands': 336,\n",
       " 'gold': 337,\n",
       " 'imma': 338,\n",
       " 'ask': 339,\n",
       " 'half': 340,\n",
       " 'music': 341,\n",
       " 'times': 342,\n",
       " 'feeling': 343,\n",
       " 'step': 344,\n",
       " 'end': 345,\n",
       " 'bust': 346,\n",
       " 'hope': 347,\n",
       " 'pain': 348,\n",
       " 'probably': 349,\n",
       " 'crew': 350,\n",
       " 'crazy': 351,\n",
       " 'plus': 352,\n",
       " 'hes': 353,\n",
       " 'broke': 354,\n",
       " 'talking': 355,\n",
       " 'sound': 356,\n",
       " 'brain': 357,\n",
       " 'rappers': 358,\n",
       " 'yes': 359,\n",
       " 'id': 360,\n",
       " 'pay': 361,\n",
       " 'coming': 362,\n",
       " 'wrong': 363,\n",
       " 'under': 364,\n",
       " 'peace': 365,\n",
       " 'side': 366,\n",
       " 'knew': 367,\n",
       " 'caught': 368,\n",
       " 'weed': 369,\n",
       " 'line': 370,\n",
       " 'school': 371,\n",
       " 'red': 372,\n",
       " 'tryin': 373,\n",
       " 'pass': 374,\n",
       " 'cash': 375,\n",
       " 'words': 376,\n",
       " 'rhymes': 377,\n",
       " 'ready': 378,\n",
       " 'maybe': 379,\n",
       " 'dope': 380,\n",
       " 'remember': 381,\n",
       " 'mine': 382,\n",
       " 'wasnt': 383,\n",
       " 'please': 384,\n",
       " 'youll': 385,\n",
       " 'king': 386,\n",
       " 'true': 387,\n",
       " 'girls': 388,\n",
       " 'doing': 389,\n",
       " 'gave': 390,\n",
       " 'brother': 391,\n",
       " 'friends': 392,\n",
       " 'myself': 393,\n",
       " 'low': 394,\n",
       " 'nobody': 395,\n",
       " 'stand': 396,\n",
       " 'must': 397,\n",
       " 'mouth': 398,\n",
       " 'act': 399,\n",
       " 'past': 400,\n",
       " 'talkin': 401,\n",
       " 'nah': 402,\n",
       " 'type': 403,\n",
       " 'truth': 404,\n",
       " 'ho': 405,\n",
       " 'war': 406,\n",
       " 'homie': 407,\n",
       " 'matter': 408,\n",
       " 'huh': 409,\n",
       " 'spot': 410,\n",
       " 'sleep': 411,\n",
       " 'four': 412,\n",
       " 'guns': 413,\n",
       " 'hey': 414,\n",
       " 'car': 415,\n",
       " 'different': 416,\n",
       " 'party': 417,\n",
       " 'fall': 418,\n",
       " 'couple': 419,\n",
       " 'slow': 420,\n",
       " 'quick': 421,\n",
       " 'shoot': 422,\n",
       " 'fire': 423,\n",
       " 'dog': 424,\n",
       " 'once': 425,\n",
       " 'speak': 426,\n",
       " 'fast': 427,\n",
       " 'motherfucker': 428,\n",
       " 'door': 429,\n",
       " 'eye': 430,\n",
       " 'making': 431,\n",
       " 'till': 432,\n",
       " 'somebody': 433,\n",
       " 'sure': 434,\n",
       " 'started': 435,\n",
       " 'mcs': 436,\n",
       " 'song': 437,\n",
       " 'write': 438,\n",
       " 'dream': 439,\n",
       " 'nothin': 440,\n",
       " 'paper': 441,\n",
       " 'use': 442,\n",
       " 'five': 443,\n",
       " 'feet': 444,\n",
       " 'behind': 445,\n",
       " 'fake': 446,\n",
       " 'fucked': 447,\n",
       " 'lookin': 448,\n",
       " 'beef': 449,\n",
       " 'born': 450,\n",
       " 'kick': 451,\n",
       " 'respect': 452,\n",
       " 'cool': 453,\n",
       " 'being': 454,\n",
       " 'cops': 455,\n",
       " 'water': 456,\n",
       " 'close': 457,\n",
       " 'cats': 458,\n",
       " 'rest': 459,\n",
       " 'livin': 460,\n",
       " 'brothers': 461,\n",
       " 'wit': 462,\n",
       " 'heat': 463,\n",
       " 'wait': 464,\n",
       " 'already': 465,\n",
       " 'room': 466,\n",
       " 'gets': 467,\n",
       " 'team': 468,\n",
       " 'rich': 469,\n",
       " 'tried': 470,\n",
       " 'sick': 471,\n",
       " 'sun': 472,\n",
       " 'raw': 473,\n",
       " 'ice': 474,\n",
       " 'shes': 475,\n",
       " 'somethin': 476,\n",
       " 'shots': 477,\n",
       " 'touch': 478,\n",
       " 'fight': 479,\n",
       " 'wild': 480,\n",
       " 'thinking': 481,\n",
       " 'wish': 482,\n",
       " 'fact': 483,\n",
       " 'blue': 484,\n",
       " 'nice': 485,\n",
       " 'mama': 486,\n",
       " 'far': 487,\n",
       " 'lay': 488,\n",
       " 'part': 489,\n",
       " 'lord': 490,\n",
       " 'paid': 491,\n",
       " 'understand': 492,\n",
       " 'smoking': 493,\n",
       " 'year': 494,\n",
       " 'running': 495,\n",
       " 'murder': 496,\n",
       " 'lose': 497,\n",
       " 'sit': 498,\n",
       " 'round': 499,\n",
       " 'green': 500,\n",
       " 'g': 501,\n",
       " 'fresh': 502,\n",
       " 'cop': 503,\n",
       " 'hundred': 504,\n",
       " 'dough': 505,\n",
       " 'flip': 506,\n",
       " 'burn': 507,\n",
       " 'floor': 508,\n",
       " 'shine': 509,\n",
       " 'whos': 510,\n",
       " 'dark': 511,\n",
       " 'club': 512,\n",
       " 'second': 513,\n",
       " 'comin': 514,\n",
       " 'family': 515,\n",
       " 'grab': 516,\n",
       " 'fat': 517,\n",
       " 'york': 518,\n",
       " 'goes': 519,\n",
       " 'air': 520,\n",
       " 'ghetto': 521,\n",
       " 'has': 522,\n",
       " 'dreams': 523,\n",
       " 'power': 524,\n",
       " 'neck': 525,\n",
       " 'momma': 526,\n",
       " 'beats': 527,\n",
       " 'chain': 528,\n",
       " 'stuck': 529,\n",
       " 'help': 530,\n",
       " 'ones': 531,\n",
       " 'yourself': 532,\n",
       " 'drink': 533,\n",
       " 'six': 534,\n",
       " 'bet': 535,\n",
       " 'plan': 536,\n",
       " 'track': 537,\n",
       " 'dirty': 538,\n",
       " 'hop': 539,\n",
       " 'business': 540,\n",
       " 'feelin': 541,\n",
       " 'few': 542,\n",
       " 'phone': 543,\n",
       " 'wonder': 544,\n",
       " 'found': 545,\n",
       " 'yet': 546,\n",
       " 'care': 547,\n",
       " 'sometimes': 548,\n",
       " 'trust': 549,\n",
       " 'forever': 550,\n",
       " 'sky': 551,\n",
       " 'women': 552,\n",
       " 'shorty': 553,\n",
       " 'drugs': 554,\n",
       " 'taking': 555,\n",
       " 'push': 556,\n",
       " 'tight': 557,\n",
       " 'pretty': 558,\n",
       " 'million': 559,\n",
       " 'strong': 560,\n",
       " 'ball': 561,\n",
       " 'stick': 562,\n",
       " 'bag': 563,\n",
       " 'cuz': 564,\n",
       " 'comes': 565,\n",
       " 'rather': 566,\n",
       " 'goin': 567,\n",
       " 'buy': 568,\n",
       " 'thoughts': 569,\n",
       " 'point': 570,\n",
       " 'daddy': 571,\n",
       " 'land': 572,\n",
       " 'reason': 573,\n",
       " 'fear': 574,\n",
       " 'earth': 575,\n",
       " 'crib': 576,\n",
       " 'men': 577,\n",
       " 'miss': 578,\n",
       " 'alone': 579,\n",
       " 'soon': 580,\n",
       " 'called': 581,\n",
       " 'dollar': 582,\n",
       " 'ten': 583,\n",
       " 'wanted': 584,\n",
       " 'saw': 585,\n",
       " 'together': 586,\n",
       " 'meet': 587,\n",
       " 'both': 588,\n",
       " 'hiphop': 589,\n",
       " 'clothes': 590,\n",
       " 'box': 591,\n",
       " 'friend': 592,\n",
       " 'number': 593,\n",
       " 'locked': 594,\n",
       " 'state': 595,\n",
       " 'nine': 596,\n",
       " 'hair': 597,\n",
       " 'between': 598,\n",
       " 'picture': 599,\n",
       " 'deal': 600,\n",
       " 'lights': 601,\n",
       " 'sex': 602,\n",
       " 'mother': 603,\n",
       " 'swear': 604,\n",
       " 'jump': 605,\n",
       " 'follow': 606,\n",
       " 'corner': 607,\n",
       " 'saying': 608,\n",
       " 'felt': 609,\n",
       " 'known': 610,\n",
       " 'late': 611,\n",
       " 'wake': 612,\n",
       " 'food': 613,\n",
       " 'child': 614,\n",
       " 'forget': 615,\n",
       " 'case': 616,\n",
       " 'police': 617,\n",
       " 'sell': 618,\n",
       " 'town': 619,\n",
       " 'bang': 620,\n",
       " 'lil': 621,\n",
       " 'pray': 622,\n",
       " 'whatever': 623,\n",
       " 'motherfuckers': 624,\n",
       " 'wall': 625,\n",
       " 'pick': 626,\n",
       " 'crime': 627,\n",
       " 'read': 628,\n",
       " 'great': 629,\n",
       " 'against': 630,\n",
       " 'shoes': 631,\n",
       " 'doin': 632,\n",
       " 'piece': 633,\n",
       " 'rapper': 634,\n",
       " 'fame': 635,\n",
       " 'met': 636,\n",
       " 'theyre': 637,\n",
       " 'bought': 638,\n",
       " 'each': 639,\n",
       " 'scared': 640,\n",
       " 'yawk': 641,\n",
       " 'road': 642,\n",
       " 'boys': 643,\n",
       " 'drive': 644,\n",
       " 'dance': 645,\n",
       " 'record': 646,\n",
       " 'means': 647,\n",
       " 'makin': 648,\n",
       " 'wouldnt': 649,\n",
       " 'job': 650,\n",
       " 'devil': 651,\n",
       " 'star': 652,\n",
       " 'clear': 653,\n",
       " 'drug': 654,\n",
       " 'send': 655,\n",
       " 'la': 656,\n",
       " 'blast': 657,\n",
       " 'wear': 658,\n",
       " 'kiss': 659,\n",
       " 'mr': 660,\n",
       " 'lie': 661,\n",
       " 'bit': 662,\n",
       " 'alive': 663,\n",
       " 'nas': 664,\n",
       " 'skin': 665,\n",
       " 'cream': 666,\n",
       " 'uhh': 667,\n",
       " 'brown': 668,\n",
       " 'turned': 669,\n",
       " 'makes': 670,\n",
       " 'save': 671,\n",
       " 'very': 672,\n",
       " 'today': 673,\n",
       " 'whip': 674,\n",
       " 'system': 675,\n",
       " 'blunt': 676,\n",
       " 'sold': 677,\n",
       " 'lead': 678,\n",
       " 'rain': 679,\n",
       " 'brooklyn': 680,\n",
       " 'grow': 681,\n",
       " 'lyrics': 682,\n",
       " 'park': 683,\n",
       " 'fine': 684,\n",
       " 'double': 685,\n",
       " 'kept': 686,\n",
       " 'shake': 687,\n",
       " 'runnin': 688,\n",
       " 'breath': 689,\n",
       " 'thinkin': 690,\n",
       " 'pack': 691,\n",
       " 'fool': 692,\n",
       " 'later': 693,\n",
       " 'ring': 694,\n",
       " 'chest': 695,\n",
       " 'yours': 696,\n",
       " 'hurt': 697,\n",
       " 'which': 698,\n",
       " 'pen': 699,\n",
       " 'chill': 700,\n",
       " 'mc': 701,\n",
       " 'either': 702,\n",
       " 'brought': 703,\n",
       " 'changed': 704,\n",
       " 'kind': 705,\n",
       " 'none': 706,\n",
       " 'clean': 707,\n",
       " 'dirt': 708,\n",
       " 'west': 709,\n",
       " 'coke': 710,\n",
       " 'verse': 711,\n",
       " 'cat': 712,\n",
       " 'glass': 713,\n",
       " 'learn': 714,\n",
       " 'playing': 715,\n",
       " 'control': 716,\n",
       " 'chick': 717,\n",
       " 'bread': 718,\n",
       " 'smile': 719,\n",
       " 'outta': 720,\n",
       " 'gang': 721,\n",
       " 'week': 722,\n",
       " 'wife': 723,\n",
       " 'class': 724,\n",
       " 'heavy': 725,\n",
       " 'stars': 726,\n",
       " 'ground': 727,\n",
       " 'reach': 728,\n",
       " 'scene': 729,\n",
       " 'played': 730,\n",
       " 'ha': 731,\n",
       " 'sweet': 732,\n",
       " 'ways': 733,\n",
       " 'cars': 734,\n",
       " 'hip': 735,\n",
       " 'haters': 736,\n",
       " 'less': 737,\n",
       " 'dude': 738,\n",
       " 'window': 739,\n",
       " 'minute': 740,\n",
       " 'sing': 741,\n",
       " 'kinda': 742,\n",
       " 'woo': 743,\n",
       " 'thousand': 744,\n",
       " 'test': 745,\n",
       " 'drama': 746,\n",
       " 'bigger': 747,\n",
       " 'father': 748,\n",
       " 'bars': 749,\n",
       " 'weak': 750,\n",
       " 'stage': 751,\n",
       " 'killed': 752,\n",
       " 'outside': 753,\n",
       " 'bullshit': 754,\n",
       " 'wet': 755,\n",
       " 'boss': 756,\n",
       " 'queens': 757,\n",
       " 'rip': 758,\n",
       " 'worth': 759,\n",
       " 'ran': 760,\n",
       " 'morning': 761,\n",
       " 'waiting': 762,\n",
       " 'thug': 763,\n",
       " 'taste': 764,\n",
       " 'wrote': 765,\n",
       " 'sayin': 766,\n",
       " 'funny': 767,\n",
       " 'hustle': 768,\n",
       " 'grown': 769,\n",
       " 'okay': 770,\n",
       " 'coast': 771,\n",
       " 'bed': 772,\n",
       " 'raps': 773,\n",
       " 'voice': 774,\n",
       " 'story': 775,\n",
       " 'perfect': 776,\n",
       " 'future': 777,\n",
       " 'anything': 778,\n",
       " 'dumb': 779,\n",
       " 'smokin': 780,\n",
       " 'doubt': 781,\n",
       " 'loud': 782,\n",
       " 'watching': 783,\n",
       " 'moms': 784,\n",
       " 'crowd': 785,\n",
       " 'ah': 786,\n",
       " 'problem': 787,\n",
       " 'homies': 788,\n",
       " 'level': 789,\n",
       " 'win': 790,\n",
       " 'split': 791,\n",
       " 'knock': 792,\n",
       " 'pocket': 793,\n",
       " 'killer': 794,\n",
       " 'heads': 795,\n",
       " 'may': 796,\n",
       " 'children': 797,\n",
       " 'rolling': 798,\n",
       " 'switch': 799,\n",
       " 'easy': 800,\n",
       " 'holding': 801,\n",
       " 'buck': 802,\n",
       " 'playin': 803,\n",
       " 'vision': 804,\n",
       " 'small': 805,\n",
       " 'tonight': 806,\n",
       " 'album': 807,\n",
       " 'flows': 808,\n",
       " 'seems': 809,\n",
       " 'soft': 810,\n",
       " 'cry': 811,\n",
       " 'gods': 812,\n",
       " 'moment': 813,\n",
       " 'master': 814,\n",
       " 'moving': 815,\n",
       " 'hang': 816,\n",
       " 'takin': 817,\n",
       " 'pimp': 818,\n",
       " 'bar': 819,\n",
       " 'stress': 820,\n",
       " 'suck': 821,\n",
       " 'else': 822,\n",
       " 'poor': 823,\n",
       " 'gat': 824,\n",
       " '2': 825,\n",
       " 'across': 826,\n",
       " 'trip': 827,\n",
       " 'd': 828,\n",
       " 'lady': 829,\n",
       " 'heaven': 830,\n",
       " 'store': 831,\n",
       " 'fiends': 832,\n",
       " 'space': 833,\n",
       " 'seven': 834,\n",
       " 'figure': 835,\n",
       " 'heres': 836,\n",
       " 'fit': 837,\n",
       " 'rocks': 838,\n",
       " 'spend': 839,\n",
       " 'question': 840,\n",
       " 'bottom': 841,\n",
       " 'bomb': 842,\n",
       " 'handle': 843,\n",
       " 'chicks': 844,\n",
       " 'telling': 845,\n",
       " 'lies': 846,\n",
       " 'knows': 847,\n",
       " 'laugh': 848,\n",
       " 'third': 849,\n",
       " 'blind': 850,\n",
       " 'dollars': 851,\n",
       " 'laid': 852,\n",
       " 'mans': 853,\n",
       " 'upon': 854,\n",
       " 'jay': 855,\n",
       " 'bank': 856,\n",
       " 'loose': 857,\n",
       " 'walking': 858,\n",
       " 'drunk': 859,\n",
       " 'finger': 860,\n",
       " 'thank': 861,\n",
       " 'summer': 862,\n",
       " 'within': 863,\n",
       " 'tip': 864,\n",
       " 'short': 865,\n",
       " 'supposed': 866,\n",
       " 'hide': 867,\n",
       " 'tears': 868,\n",
       " 'mom': 869,\n",
       " 'chance': 870,\n",
       " 'killing': 871,\n",
       " 'least': 872,\n",
       " 'does': 873,\n",
       " 'diamonds': 874,\n",
       " 'sorry': 875,\n",
       " 'woman': 876,\n",
       " 'single': 877,\n",
       " 'bone': 878,\n",
       " 'tracks': 879,\n",
       " 'peep': 880,\n",
       " 'art': 881,\n",
       " 'lines': 882,\n",
       " 'feed': 883,\n",
       " 'zone': 884,\n",
       " 'wack': 885,\n",
       " 'shut': 886,\n",
       " 'along': 887,\n",
       " 'fell': 888,\n",
       " 'nose': 889,\n",
       " 'jail': 890,\n",
       " 'knowledge': 891,\n",
       " 'fans': 892,\n",
       " 'middle': 893,\n",
       " 'minds': 894,\n",
       " 'liquor': 895,\n",
       " 'motherfucking': 896,\n",
       " 'ladies': 897,\n",
       " 'safe': 898,\n",
       " 'spread': 899,\n",
       " 'everyday': 900,\n",
       " 'beautiful': 901,\n",
       " 'trap': 902,\n",
       " 'giving': 903,\n",
       " 'train': 904,\n",
       " 'arm': 905,\n",
       " 'thugs': 906,\n",
       " 'south': 907,\n",
       " 'glock': 908,\n",
       " 'raise': 909,\n",
       " 'benz': 910,\n",
       " 'jewels': 911,\n",
       " 'smell': 912,\n",
       " 'teeth': 913,\n",
       " 'stupid': 914,\n",
       " 'youve': 915,\n",
       " 'wind': 916,\n",
       " 'jesus': 917,\n",
       " 'motherfuckin': 918,\n",
       " 'sitting': 919,\n",
       " 'sign': 920,\n",
       " 'ahead': 921,\n",
       " 'clip': 922,\n",
       " 'quit': 923,\n",
       " 'seat': 924,\n",
       " 'dropped': 925,\n",
       " 'lock': 926,\n",
       " 'happen': 927,\n",
       " 'course': 928,\n",
       " 'having': 929,\n",
       " 'grip': 930,\n",
       " 'blame': 931,\n",
       " 'build': 932,\n",
       " 'count': 933,\n",
       " 'dudes': 934,\n",
       " 'above': 935,\n",
       " 'pants': 936,\n",
       " 'tv': 937,\n",
       " 'building': 938,\n",
       " 'ayo': 939,\n",
       " 'bullets': 940,\n",
       " 'bus': 941,\n",
       " 'hits': 942,\n",
       " 'died': 943,\n",
       " 'holdin': 944,\n",
       " 'force': 945,\n",
       " 'gs': 946,\n",
       " 'kitchen': 947,\n",
       " 'pound': 948,\n",
       " 'weight': 949,\n",
       " 'dig': 950,\n",
       " 'paint': 951,\n",
       " 'promise': 952,\n",
       " 'sweat': 953,\n",
       " 'ooh': 954,\n",
       " 'seem': 955,\n",
       " 'tired': 956,\n",
       " 'bottle': 957,\n",
       " 'tongue': 958,\n",
       " 'favorite': 959,\n",
       " 'beast': 960,\n",
       " 'order': 961,\n",
       " 'book': 962,\n",
       " 'b': 963,\n",
       " 'sense': 964,\n",
       " 'pockets': 965,\n",
       " 'nights': 966,\n",
       " 'shows': 967,\n",
       " 'eating': 968,\n",
       " 'fun': 969,\n",
       " 'grind': 970,\n",
       " 'juice': 971,\n",
       " 'cross': 972,\n",
       " 'raised': 973,\n",
       " 'rise': 974,\n",
       " 'happy': 975,\n",
       " 'jeans': 976,\n",
       " 'jam': 977,\n",
       " 'rep': 978,\n",
       " 'lips': 979,\n",
       " 'guy': 980,\n",
       " 'songs': 981,\n",
       " 'extra': 982,\n",
       " 'tape': 983,\n",
       " 'ghost': 984,\n",
       " 'tour': 985,\n",
       " 'sippin': 986,\n",
       " 'cheese': 987,\n",
       " 'hov': 988,\n",
       " 'court': 989,\n",
       " 'lick': 990,\n",
       " 'riding': 991,\n",
       " 'blunts': 992,\n",
       " 'near': 993,\n",
       " 'treat': 994,\n",
       " 'keys': 995,\n",
       " 'gas': 996,\n",
       " 'speed': 997,\n",
       " 'cock': 998,\n",
       " 'mental': 999,\n",
       " 'sent': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = inp_sequences\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len+1, padding='pre'))\n",
    "\n",
    "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1552419, 64), (1552419,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, label, test_size=0.10, shuffle=False, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.57479 ,  0.27959 , -0.17003 ,  1.0926  , -0.5678  ,  0.13946 ,\n",
       "       -0.22845 ,  0.27979 ,  0.1436  ,  0.25408 ,  0.14175 ,  0.47737 ,\n",
       "       -4.1063  , -0.45932 , -0.78775 , -0.061295,  0.28098 ,  0.55691 ,\n",
       "        0.040097, -0.33675 ,  0.10952 ,  0.32482 , -0.60996 ,  0.77837 ,\n",
       "        1.0855  ,  0.092512, -0.34347 , -0.52561 , -0.32974 , -0.45062 ,\n",
       "       -0.33763 ,  0.26943 , -0.7608  , -0.013459, -0.097348, -0.40263 ,\n",
       "        0.22523 ,  0.40602 ,  0.34765 , -1.2264  , -0.81516 , -0.57451 ,\n",
       "        0.084248,  0.36518 ,  0.24649 , -0.26708 ,  0.074   ,  0.73033 ,\n",
       "       -0.34619 ,  0.29964 ,  0.49903 ,  0.46251 , -0.68305 , -0.92597 ,\n",
       "        0.075895, -0.51661 , -0.67615 , -0.017943, -1.1911  , -0.12817 ,\n",
       "        0.27478 , -0.77928 , -0.35465 ,  0.39712 ,  0.22347 ,  0.38169 ,\n",
       "       -0.067566, -0.24608 ,  0.34249 , -0.26701 , -0.78815 , -0.79426 ,\n",
       "       -0.57019 ,  0.14404 ,  0.23621 , -0.067121,  0.31948 ,  0.06233 ,\n",
       "       -0.3619  , -0.012909,  0.91253 ,  0.21408 ,  0.12472 , -0.64596 ,\n",
       "        0.12799 ,  0.11704 , -0.66266 ,  0.31085 , -0.3327  , -0.2197  ,\n",
       "        0.4885  ,  0.42261 , -0.19855 , -0.081162,  0.015766, -0.12767 ,\n",
       "       -0.062801,  0.67944 ,  0.65676 , -0.19021 ], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.get_vector('word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    \"\"\"\n",
    "    Creates a Keras Embedding() layer and loads in pre-trained GloVe 50-dimensional vectors.\n",
    "    \n",
    "    Arguments:\n",
    "    word_to_vec_map -- dictionary mapping words to their GloVe vector representation.\n",
    "    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n",
    "\n",
    "    Returns:\n",
    "    embedding_layer -- pretrained layer Keras instance\n",
    "    \"\"\"\n",
    "    \n",
    "    vocab_len = len(word_to_index) + 1                  # adding 1 to fit Keras embedding (requirement)\n",
    "    emb_dim = word_vectors.get_vector(\"cucumber\").shape[0]      # define dimensionality of your GloVe word vectors (= 50)\n",
    "    emb_dim_one = word_vectors.get_vector(\"cucumber\").shape\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    # Step 1\n",
    "    # Initialize the embedding matrix as a numpy array of zeros.\n",
    "    # See instructions above to choose the correct shape.\n",
    "    emb_matrix = np.zeros((vocab_len, emb_dim))\n",
    "    \n",
    "    # Step 2\n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        try:\n",
    "            emb_matrix[idx, :] = word_vectors.get_vector(word)\n",
    "        except KeyError:\n",
    "            emb_matrix[idx, :] = np.random.rand(emb_dim)#np.zeros(word_vectors.get_vector(\"cucumber\").shape)\n",
    "\n",
    "    # Step 3\n",
    "    # Define Keras embedding layer with the correct input and output sizes\n",
    "    # Make it non-trainable.\n",
    "    embedding_layer = tensorflow.keras.layers.Embedding(input_dim=vocab_len, output_dim=emb_dim, trainable=True, mask_zero=True)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Step 4 (already done for you; please do not modify)\n",
    "    # Build the embedding layer, it is required before setting the weights of the embedding layer. \n",
    "    embedding_layer.build((None,)) # Do not modify the \"None\".  This line of code is complete as-is.\n",
    "    \n",
    "    # Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = pretrained_embedding_layer(word_vectors, tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 64, 100)           5012100   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64, 256)           365568    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50121)             12881097  \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 50121)             0         \n",
      "=================================================================\n",
      "Total params: 18,784,077\n",
      "Trainable params: 18,784,077\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (max_sequence_len,)\n",
    "print(max_sequence_len)\n",
    "sentence_indices = Input(shape=input_shape, dtype='int32')\n",
    "    \n",
    "# Create the embedding layer pretrained with GloVe Vectors (â‰ˆ1 line)\n",
    "embedding_layer = pretrained_embedding_layer(word_vectors, tokenizer.word_index)\n",
    "\n",
    "# Propagate sentence_indices through your embedding layer\n",
    "# (See additional hints in the instructions).\n",
    "embeddings = embedding_layer(sentence_indices) \n",
    "\n",
    "# Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
    "# The returned output should be a batch of sequences.\n",
    "X = LSTM(units=256, return_sequences=True)(embeddings)\n",
    "# Add dropout with a probability of 0.5\n",
    "X = Dropout(rate=0.5)(X)\n",
    "# Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "# The returned output should be a single hidden state, not a batch of sequences.\n",
    "X = LSTM(units=256, return_sequences=False)(X)\n",
    "# Add dropout with a probability of 0.5\n",
    "X = Dropout(rate=0.5)(X)\n",
    "# Propagate X through a Dense layer with 5 units\n",
    "X = Dense(units=total_words)(X)\n",
    "# Add a softmax activation\n",
    "X = Activation('softmax')(X)\n",
    "\n",
    "\n",
    "\n",
    "# Create Model instance which converts sentence_indices into X.\n",
    "model = Model(inputs=sentence_indices, outputs=X)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, _):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "    text = flattened_list\n",
    "    start_index = random.randint(0, len(text) - max_sequence_len - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(40):\n",
    "            x_pred = [tokenizer.word_index[i] for i in sentence.split()]\n",
    "            x_pred = np.array(pad_sequences([[tokenizer.word_index[i] for i in sentence.split()]], maxlen=max_sequence_len, padding='pre'))\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = ' ' + tokenizer.index_word[next_index]\n",
    "            \n",
    "            sentence = sentence + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 936108 samples, validate on 461069 samples\n",
      "Epoch 1/25\n",
      " 40224/936108 [>.............................] - ETA: 3:28:26 - loss: 7.6273 - sparse_categorical_accuracy: 0.0498\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"talk real good cause im smart and stuff\"\n",
      "talk real good cause im smart and stuff"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/aesopbot/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[0;34m(self, epoch, mode)\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m       \u001b[0;32myield\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    682\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aesopbot/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aesopbot/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aesopbot/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aesopbot/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aesopbot/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aesopbot/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aesopbot/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aesopbot/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aesopbot/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aesopbot/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-bec43942d92c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sparse_categorical_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/aesopbot/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/aesopbot/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    370\u001b[0m                       total_epochs=1)\n\u001b[1;32m    371\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[0;32m--> 372\u001b[0;31m                                  prefix='val_')\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aesopbot/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aesopbot/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[0;34m(self, epoch, mode)\u001b[0m\n\u001b[1;32m    683\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0;31m# Epochs only apply to `fit`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aesopbot/lib/python3.6/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-851e74390d4f>\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(epoch, _)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mx_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mx_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_sequence_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pre'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mnext_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiversity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mnext_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnext_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aesopbot/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aesopbot/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     return self._model_iteration(\n\u001b[1;32m    461\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         steps=steps, callbacks=callbacks, **kwargs)\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aesopbot/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m               \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m               total_epochs=1)\n\u001b[0m\u001b[1;32m    445\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aesopbot/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aesopbot/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aesopbot/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aesopbot/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    524\u001b[0m               *args, **kwds)\n\u001b[1;32m    525\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aesopbot/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aesopbot/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/aesopbot/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/envs/aesopbot/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['sparse_categorical_accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs = 25, batch_size = 32, validation_split=0.33, shuffle=True,callbacks=[print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test, batch_size = 32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
